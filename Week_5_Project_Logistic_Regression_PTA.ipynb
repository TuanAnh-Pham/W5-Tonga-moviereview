{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 5  Project-Logistic Regression-PTA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4xXMKpX9qv4G",
        "kHlHez82W14V",
        "oRDT_3v3HfJU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_9Gbcgq1OQs",
        "colab_type": "text"
      },
      "source": [
        "# Predict sentiment score of moview review with Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkG5CqnzTpT_",
        "colab_type": "text"
      },
      "source": [
        "## 1.Import data & Basic library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQpoG7bO3-YY",
        "colab_type": "code",
        "outputId": "49cec7de-5c82-4df4-e7a9-27652989bf6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp9O-nm03ZZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJReFmBO33kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/FTMLE - Tonga/Data/movie_review.csv',encoding='utf-8', sep='\\t')\n",
        "ev = pd.read_csv('/content/drive/My Drive/FTMLE - Tonga/Data/movie_review_evaluation.csv',encoding='utf-8', sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmpUEs2y5rpv",
        "colab_type": "code",
        "outputId": "beea1aa2-1252-47e7-9d68-831ac4bb4851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Check sample of the dataset\n",
        "df.sample(5)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9374</th>\n",
              "      <td>6265_7</td>\n",
              "      <td>Nick and Kelly are ready to be married but Tra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366</th>\n",
              "      <td>7727_3</td>\n",
              "      <td>I am commenting on this miniseries from the pe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19843</th>\n",
              "      <td>10429_10</td>\n",
              "      <td>I'm not usually a fan of strictly romantic mov...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3186</th>\n",
              "      <td>12433_8</td>\n",
              "      <td>This is a good movie, although people unfamili...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>5774_1</td>\n",
              "      <td>This movie is a modest effort by Spike Lee. He...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id                                             review  sentiment\n",
              "9374     6265_7  Nick and Kelly are ready to be married but Tra...          1\n",
              "1366     7727_3  I am commenting on this miniseries from the pe...          0\n",
              "19843  10429_10  I'm not usually a fan of strictly romantic mov...          1\n",
              "3186    12433_8  This is a good movie, although people unfamili...          1\n",
              "2766     5774_1  This movie is a modest effort by Spike Lee. He...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7y8t-8oT0Cx",
        "colab_type": "text"
      },
      "source": [
        "## 2.Overview of the data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTNjpY26UfPd",
        "colab_type": "code",
        "outputId": "57dca89d-084a-4214-e10f-0a0add86095e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Check content of 1 comment for the meaning of sentiment\n",
        "# 0 means negative ; 1 means positive\n",
        "df.loc[2196,'review']"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This was awful. Andie Macdowell is a terrible actress. So wooden she makes a rocking horse look like it could do a better job. But then remember that turn in Four Weddings, equally as excruciating. Another film that portrays England as full of Chocolate box cottages, and village greens. I mean that school, how many schools apart from maybe Hogwarts look like that? The twee police station looked like the set from Heartbeat ( a nauseating British series set in the 60s).This film just couldn't make its mind up what it wanted to be- a comedy or a serious examination of the undercurrents in women's friendships. If it had stuck to the former then the graveyard sex scenes and the highly stupid storming of the wedding might just have worked( i say just). But those scenes just didn't work with the tragedy in the second half. I also find it implausible that Kate would ever speak to Molly again after her terrible behaviour. A final note- what is a decent actress like Staunton doing in this pile of poo? Not to mention Anna Chancellor. Macdowell should stick to advertising wrinkle cream.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAe38mWUhJjE",
        "colab_type": "code",
        "outputId": "2722bf2c-1465-4318-d07f-8d70a7bf672a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "df.info()\n",
        "# There is no missing data"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22500 entries, 0 to 22499\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         22500 non-null  object\n",
            " 1   review     22500 non-null  object\n",
            " 2   sentiment  22500 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 527.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRfDTw576qHP",
        "colab_type": "code",
        "outputId": "8d1b4772-2b43-4a5c-cb62-6b3851dc9549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['sentiment'].value_counts(normalize= True)\n",
        "\n",
        "# There is only 2 tye of sentiment, 0 and 1. \n",
        "# 0 means negative ; 1 means positive"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.501244\n",
              "0    0.498756\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq1d_GrV7p8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for duplicate id ->  No duplicate found\n",
        "df['id'].count() == df['id'].nunique()\n",
        "\n",
        "# It does not support our prediction model so we can remove it \n",
        "df.drop(labels='id',axis=1,inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8KGO3zapLQ9",
        "colab_type": "code",
        "outputId": "36947904-8855-4fd2-c9ea-4e51024d9060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>With all this stuff going down at the moment w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It must be assumed that those who praised this...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22495</th>\n",
              "      <td>It seems like more consideration has gone into...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22496</th>\n",
              "      <td>I don't believe they made this film. Completel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22497</th>\n",
              "      <td>Guy is a loser. Can't get girls, needs to buil...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22498</th>\n",
              "      <td>This 30 minute documentary BuÃ±uel made in the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22499</th>\n",
              "      <td>I saw this movie as a child and it broke my he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "0      With all this stuff going down at the moment w...          1\n",
              "1      \\The Classic War of the Worlds\\\" by Timothy Hi...          1\n",
              "2      The film starts with a manager (Nicholas Bell)...          0\n",
              "3      It must be assumed that those who praised this...          0\n",
              "4      Superbly trashy and wondrously unpretentious 8...          1\n",
              "...                                                  ...        ...\n",
              "22495  It seems like more consideration has gone into...          0\n",
              "22496  I don't believe they made this film. Completel...          0\n",
              "22497  Guy is a loser. Can't get girls, needs to buil...          0\n",
              "22498  This 30 minute documentary BuÃ±uel made in the...          0\n",
              "22499  I saw this movie as a child and it broke my he...          1\n",
              "\n",
              "[22500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLtA_3g6UDkR",
        "colab_type": "code",
        "outputId": "f4ff9452-84d3-4caf-c85d-22e6c5f9a32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check for duplicate review -> there are duplicated review (could be fake reviews)\n",
        "# We will check some sample of duplicate review\n",
        "df['review'].count() == df['review'].nunique()\n"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt74h9TxUONc",
        "colab_type": "code",
        "outputId": "ee96a35b-95be-4385-cdcb-7452bda8c698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Sort the df base Columns review & Separate the duplicated review to check\n",
        "df.sort_values('review', inplace = True)\n",
        "df"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7381</th>\n",
              "      <td>\b\b\b\bA Turkish Bath sequence in a film noir loc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>!!!! POSSIBLE MILD SPOILER !!!!!&lt;br /&gt;&lt;br /&gt;As...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5741</th>\n",
              "      <td>!!!!! OF COURSE THERE'S SPOILERS !!!!! I'm sur...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7836</th>\n",
              "      <td>!!!!! POSSIBLE SPOILER !!!!!&lt;br /&gt;&lt;br /&gt;You`d ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>### Spoilers! ### &lt;br /&gt;&lt;br /&gt;What is this mov...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3403</th>\n",
              "      <td>you must be seeing my comments over many films...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19068</th>\n",
              "      <td>zero day is based of columbine high school mas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17180</th>\n",
              "      <td>{Possible spoilers coming up... you've been fo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10232</th>\n",
              "      <td>{rant start} I didn't want to believe them at ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4602</th>\n",
              "      <td>~~I was able to see this movie yesterday morni...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "7381   \b\b\b\bA Turkish Bath sequence in a film noir loc...          1\n",
              "318    !!!! POSSIBLE MILD SPOILER !!!!!<br /><br />As...          0\n",
              "5741   !!!!! OF COURSE THERE'S SPOILERS !!!!! I'm sur...          0\n",
              "7836   !!!!! POSSIBLE SPOILER !!!!!<br /><br />You`d ...          0\n",
              "378    ### Spoilers! ### <br /><br />What is this mov...          0\n",
              "...                                                  ...        ...\n",
              "3403   you must be seeing my comments over many films...          0\n",
              "19068  zero day is based of columbine high school mas...          1\n",
              "17180  {Possible spoilers coming up... you've been fo...          1\n",
              "10232  {rant start} I didn't want to believe them at ...          0\n",
              "4602   ~~I was able to see this movie yesterday morni...          1\n",
              "\n",
              "[22500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HWBwY-FWVcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check = df[df['review'].duplicated()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B4flo4bZyL6",
        "colab_type": "code",
        "outputId": "9a85bdc4-ac32-4732-8fea-1e09f3eb65a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "check\n",
        "# Look like therer is no duplicate review"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13252</th>\n",
              "      <td>'Dead Letter Office' is a low-budget film abou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6311</th>\n",
              "      <td>.......Playing Kaddiddlehopper, Col San Fernan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19066</th>\n",
              "      <td>&lt;br /&gt;&lt;br /&gt;Back in his youth, the old man had...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6658</th>\n",
              "      <td>A have a female friend who is currently being ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4441</th>\n",
              "      <td>A longtime fan of Bette Midler, I must say her...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2783</th>\n",
              "      <td>Wow, here it finally is; the action \\movie\\\" w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20989</th>\n",
              "      <td>You do realize that you've been watching the E...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>in this movie, joe pesci slams dunks a basketb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20020</th>\n",
              "      <td>it's amazing that so many people that i know h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11203</th>\n",
              "      <td>this movie begins with an ordinary funeral... ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "13252  'Dead Letter Office' is a low-budget film abou...          0\n",
              "6311   .......Playing Kaddiddlehopper, Col San Fernan...          1\n",
              "19066  <br /><br />Back in his youth, the old man had...          0\n",
              "6658   A have a female friend who is currently being ...          1\n",
              "4441   A longtime fan of Bette Midler, I must say her...          1\n",
              "...                                                  ...        ...\n",
              "2783   Wow, here it finally is; the action \\movie\\\" w...          0\n",
              "20989  You do realize that you've been watching the E...          0\n",
              "2415   in this movie, joe pesci slams dunks a basketb...          0\n",
              "20020  it's amazing that so many people that i know h...          1\n",
              "11203  this movie begins with an ordinary funeral... ...          0\n",
              "\n",
              "[75 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn0zwE0H2_u4",
        "colab_type": "text"
      },
      "source": [
        "# Prediction model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xXMKpX9qv4G",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "320tifd_3Afu",
        "colab_type": "code",
        "outputId": "deb2ed96-1ae8-4312-c974-d901ef54bae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# The special character could be recognize as part of the word & confuse our model\n",
        "# So we need to clean these special characters (astrophoe,the comma,..)\n",
        "df.sample(5)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8550</th>\n",
              "      <td>Acidic, unremitting, and beautiful, John Schle...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14802</th>\n",
              "      <td>Tony Hawk Underground came at a point where th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12637</th>\n",
              "      <td>This movie is fun to watch , doesnt have much ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1731</th>\n",
              "      <td>This is the Neil Simon piece of work that got ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5686</th>\n",
              "      <td>When I was kid back in the 1970s a local theat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "8550   Acidic, unremitting, and beautiful, John Schle...          1\n",
              "14802  Tony Hawk Underground came at a point where th...          1\n",
              "12637  This movie is fun to watch , doesnt have much ...          1\n",
              "1731   This is the Neil Simon piece of work that got ...          1\n",
              "5686   When I was kid back in the 1970s a local theat...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm6WVKu5stGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Overall look at the most common words\n",
        "from collections import Counter\n",
        "vocab = Counter()\n",
        "\n",
        "for document in df['review']:\n",
        "  for word in document.split(' '):\n",
        "    vocab[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWeWB8pkstah",
        "colab_type": "code",
        "outputId": "a7eabf89-0c67-40b3-83fc-886a3a5d625f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "vocab.most_common(20)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 258519),\n",
              " ('a', 139707),\n",
              " ('and', 137397),\n",
              " ('of', 128750),\n",
              " ('to', 119278),\n",
              " ('is', 92935),\n",
              " ('in', 77245),\n",
              " ('I', 59255),\n",
              " ('that', 57991),\n",
              " ('this', 51379),\n",
              " ('it', 48865),\n",
              " ('/><br', 45851),\n",
              " ('was', 42004),\n",
              " ('as', 38288),\n",
              " ('with', 37496),\n",
              " ('for', 36919),\n",
              " ('The', 30399),\n",
              " ('but', 30350),\n",
              " ('on', 27738),\n",
              " ('movie', 27342)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlt9dv3kOxCT",
        "colab_type": "code",
        "outputId": "8ab317fb-b3bd-4334-9ce2-8c70a3e0c07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Initiate stop word on current vocab so check for error\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "vocab_reduced = Counter()\n",
        "\n",
        "for word, count in vocab.items():\n",
        "  if not word in stop:\n",
        "    vocab_reduced[word] = count\n",
        "\n",
        "vocab_reduced.most_common(10)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 59255),\n",
              " ('/><br', 45851),\n",
              " ('The', 30399),\n",
              " ('movie', 27342),\n",
              " ('film', 24768),\n",
              " ('one', 18704),\n",
              " ('like', 16278),\n",
              " ('This', 11074),\n",
              " ('would', 10720),\n",
              " ('good', 10243)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5DntGgqstgn",
        "colab_type": "code",
        "outputId": "0ffff410-a043-48d0-e782-1ab254726d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# download stop word \n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2oQ_HSyjKof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create tokennizer function\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHlHez82W14V",
        "colab_type": "text"
      },
      "source": [
        "## Step 2 : Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXDg-7xezja8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "# #Tokenize the stop word\n",
        "# stop = tokenizer_stop(stop)\n",
        "\n",
        "def preprocessor(text):\n",
        "    \"\"\" Return a cleaned version of text\n",
        "    \"\"\"\n",
        "    # Remove HTML markup\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    # Save emoticons for later appending\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    # Remove any non-word character and append the emoticons,\n",
        "    # removing the nose character for standarization. Convert to lower case\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
        "    \n",
        "    return text\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=stop,\n",
        "                        tokenizer=tokenizer_porter,\n",
        "                        preprocessor=preprocessor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXvVfCA7xTrE",
        "colab_type": "code",
        "outputId": "5424997e-8a8b-473c-c8f4-4f71d47975f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Test our processing funtion on 1 random data\n",
        "print(df.loc[8333,'review'])\n",
        "\n",
        "preprocessor(df.loc[8333,'review'])"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To \\Bend It Like Beckham\\\" may not mean much to us Americans who know very little about the other football (soccer), but to English sports fans, it is equivalent to \\\"Hit it Like Bonds\\\" or \\\"Dunk it Like Jordan.\\\" Any young soccer player dreams of bending a soccer ball around one player and into the net for a goal, much like star player David Beckham does, much like the young Indian girl, Jess (Parminder Nagra), does in the film Bend It Like Beckham. Jess loves to play pick up soccer games, the kind forbidden by her traditionalist mother. However, while playing one day, a passing friend named Jules (Keira Knightley) sees her play and invites her to try out for a traveling, all girls soccer team. After satisfying the coach Joe (Jonathan Rhys-Meyers), she makes the team, something she knows her mother would not approve of. The movie is not about disobeying parents, but rather a girl doing what she wants to do, even if that goes against culture, not just the parents. There is humor thrown throughout the movie, especially when Jules' mother thinks she's a lesbian. The movie does resort to a bit of a clichÃ© moment, as the big soccer game is the same day as Jess' sister's wedding, but it does not come off a cheesy, but rather fun and light. The soccer action looks good, so sports fans will enjoy it, and a story about girls growing up in a boy's world, the world of soccer will inspire some in the audience. Bend It Like Beckham is not just about soccer, but rather a girl trying to find herself and please her parents at the same time, something that proves to be rather difficult.\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to bend it like beckham may not mean much to us americans who know very little about the other football soccer but to english sports fans it is equivalent to hit it like bonds or dunk it like jordan any young soccer player dreams of bending a soccer ball around one player and into the net for a goal much like star player david beckham does much like the young indian girl jess parminder nagra does in the film bend it like beckham jess loves to play pick up soccer games the kind forbidden by her traditionalist mother however while playing one day a passing friend named jules keira knightley sees her play and invites her to try out for a traveling all girls soccer team after satisfying the coach joe jonathan rhys meyers she makes the team something she knows her mother would not approve of the movie is not about disobeying parents but rather a girl doing what she wants to do even if that goes against culture not just the parents there is humor thrown throughout the movie especially when jules mother thinks she s a lesbian the movie does resort to a bit of a clichã moment as the big soccer game is the same day as jess sister s wedding but it does not come off a cheesy but rather fun and light the soccer action looks good so sports fans will enjoy it and a story about girls growing up in a boy s world the world of soccer will inspire some in the audience bend it like beckham is not just about soccer but rather a girl trying to find herself and please her parents at the same time something that proves to be rather difficult  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sykDJEtD0I0P",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quMv4bXNLguD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset in train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['review']\n",
        "\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMA_qTW5LguJ",
        "colab_type": "code",
        "outputId": "c37f0465-54e6-42d5-e78c-e3e85d37b9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# ut the process into the pipeline\n",
        "\n",
        "clf = Pipeline([('vect', tfidf),\n",
        "                ('clf', LogisticRegression(random_state=0))])\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', 'onc', 'onli', 'ourselv', 'themselv', 'thi', 'veri', 'wa', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=<function preprocessor at 0x7fe12e8d79d8>,\n",
              "                                 smooth_idf=True,\n",
              "                                 stop_words=['i', 'me', 'my', 'myself', '...\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenizer_porter at 0x7fe12e7e0d90>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=0,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yonP8E3vLguL",
        "colab_type": "code",
        "outputId": "ac3459cf-8048-460d-a209-1250eaea9a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Now apply those above metrics to evaluate your model\n",
        "\n",
        "predictions = clf.predict(X_test)\n",
        "accuracy_score(y_test, predictions)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmaY3lyrX_p5",
        "colab_type": "code",
        "outputId": "ce860b9a-7513-486b-b41e-10d7d3e514d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89      2242\n",
            "           1       0.88      0.91      0.90      2258\n",
            "\n",
            "    accuracy                           0.89      4500\n",
            "   macro avg       0.89      0.89      0.89      4500\n",
            "weighted avg       0.89      0.89      0.89      4500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HquB-fLM_gL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict the sentiment of evaluation set\n",
        "tuananh_pred = clf.predict(ev['review'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03XOz8x4cUfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export the result\n",
        "pred_result = pd.DataFrame(data=tuananh_pred)\n",
        "pred_result.to_csv('tuananh.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKfiaDbsa8-U",
        "colab_type": "text"
      },
      "source": [
        "## Model testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcgsonCxLguO",
        "colab_type": "code",
        "outputId": "adc1eeb3-445c-45aa-d634-e99b1ef529d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "review_test = [\n",
        "    \"Not the worst spoof movie that's been made, but it is a big disappointment.\",\n",
        "    \"I love this but would not recommend the movie for children\",\n",
        "    \":) this movie sucks so badly\",\n",
        "]\n",
        "\n",
        "preds = clf.predict_proba(review_test)\n",
        "\n",
        "for i in range(len(review_test)):\n",
        "    print(f'{i} --> Negative, Positive = {preds[i]}')"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 --> Negative, Positive = [0.99111058 0.00888942]\n",
            "1 --> Negative, Positive = [0.16310394 0.83689606]\n",
            "2 --> Negative, Positive = [0.82644859 0.17355141]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRDT_3v3HfJU",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression with Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRvJZu4Z9P9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "import spacy\n",
        "spacy.load('en')\n",
        "from spacy.lang.en import English\n",
        "parser = English()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3YZCyHJ--b5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))\n",
        "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\"]\n",
        "\n",
        "class CleanTextTransformer(TransformerMixin):\n",
        "   def transform(self, X, **transform_params):\n",
        "        return [cleanText(text) for text in X]\n",
        "   def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "def get_params(self, deep=True):\n",
        "        return {}\n",
        "    \n",
        "def cleanText(text):\n",
        "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "    text = text.lower()\n",
        "    return text\n",
        "def tokenizeText(sample):\n",
        "    tokens = parser(sample)\n",
        "    lemmas = []\n",
        "    for tok in tokens:\n",
        "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
        "    tokens = lemmas\n",
        "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
        "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SriE0DVETQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,1))\n",
        "clf = LinearSVC()\n",
        "\n",
        "pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNZEh_hVETN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "29688680-07c2-4e07-c350-0708379e86de"
      },
      "source": [
        "# train\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# test\n",
        "preds = pipe.predict(X_test)\n",
        "\n",
        "print(\"accuracy:\", accuracy_score(y_test, preds))"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8617777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3kyBOh2HyTM",
        "colab_type": "text"
      },
      "source": [
        "## Reference:\n",
        "[Towards Data Science: Logistic Regression with Spacy](https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}